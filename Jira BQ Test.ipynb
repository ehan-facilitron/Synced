{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19090,
     "status": "ok",
     "timestamp": 1755744708901,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "8UnuTaEdiLK-",
    "outputId": "d0317f0f-81e8-4f7f-e039-c3a715a8d2c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jira in /usr/local/lib/python3.12/dist-packages (3.10.5)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.12/dist-packages (from jira) (0.7.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from jira) (25.0)\n",
      "Requirement already satisfied: requests-oauthlib>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from jira) (2.0.0)\n",
      "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.12/dist-packages (from jira) (2.32.4)\n",
      "Requirement already satisfied: requests_toolbelt in /usr/local/lib/python3.12/dist-packages (from jira) (1.0.0)\n",
      "Requirement already satisfied: typing_extensions>=3.7.4.2 in /usr/local/lib/python3.12/dist-packages (from jira) (4.14.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->jira) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->jira) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->jira) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.10.0->jira) (2025.8.3)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib>=1.1.0->jira) (3.3.1)\n",
      "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.12/dist-packages (3.35.1)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.25.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.38.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
      "Requirement already satisfied: packaging>=24.2.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (25.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-bigquery) (2.32.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n",
      "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.38.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (2.32.4)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.12/dist-packages (from google-cloud-storage) (1.7.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.12/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install jira\n",
    "!pip install google-cloud-bigquery\n",
    "!pip install google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64876358"
   },
   "source": [
    "# Task\n",
    "Create a link between Jira and BigQuery by extracting data from Jira and loading it into BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38679288"
   },
   "source": [
    "## Setup jira connection\n",
    "\n",
    "### Subtask:\n",
    "Establish a connection to your Jira instance using appropriate libraries and credentials.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a2a7d6e"
   },
   "source": [
    "**Reasoning**:\n",
    "Import the necessary library, define credentials, create a Jira client instance, and verify the connection by getting server information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1755745525382,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "04a2026a",
    "outputId": "05a83123-6bd1-49a4-f961-e7f5a1bb3887"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jira Server Information:\n",
      "  Version: 1001.0.0-SNAPSHOT\n",
      "  Base URL: https://facilitron.atlassian.net\n"
     ]
    }
   ],
   "source": [
    "from jira import JIRA\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "# Define your Jira URL and credentials\n",
    "jira_url = \"https://facilitron.atlassian.net\"\n",
    "# jira_username = \"bseeley@facilitron.com\"\n",
    "jira_username = 'ehan@facilitron.com'\n",
    "jira_api_token = userdata.get('jira_api_token')\n",
    "print(jira_api_token)\n",
    "\n",
    "# Create an instance of the Jira client\n",
    "jira = JIRA(server=jira_url, basic_auth=(jira_username, jira_api_token))\n",
    "\n",
    "# Verify the connection by getting server information\n",
    "server_info = jira.server_info()\n",
    "print(\"Jira Server Information:\")\n",
    "print(f\"  Version: {server_info['version']}\")\n",
    "print(f\"  Base URL: {server_info['baseUrl']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1499,
     "status": "ok",
     "timestamp": 1755746055884,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "1332c352",
    "outputId": "efef52c9-7f09-40f7-afb5-9c56e2af17d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50 issues in project WORKS:\n",
      "- WORKS-3703: Spinner Endlessly Loading - Fix\n",
      "- WORKS-3702: Scheduler API: Validate Role & Pass Screen Parameter\n",
      "- WORKS-3701: Advance Search -> Location causes errors when searching for multiple words\n",
      "- WORKS-3700: Update status schema to remove reserved statuses\n",
      "- WORKS-3699: Remove reserved statuses\n",
      "- WORKS-3698: Create beamer post for remove reserved statuses\n",
      "- WORKS-3697: Cost tab screen is no longer retrieving the correct hourly labor rate, it is returning $0 for all wages.\n",
      "- WORKS-3696: Work order edit modal enhancements\n",
      "- WORKS-3695: Optimize Order List Retrieval with Lazy Loading\n",
      "- WORKS-3694: Misc Design Updates\n",
      "- WORKS-3693: String was not recognized as a valid Boolean error in Elmah\n",
      "- WORKS-3692: Fix chat window causing \"changes not be saved\" dialog\n",
      "- WORKS-3691: Added Story for the Email alert \n",
      "- WORKS-3690: Add back date parameters to tom_GetActiveWorkOrdersForProcessorPaginationV4\n",
      "- WORKS-3689: Increase dispositions to query with, Closed, Locked, Request\n",
      "- WORKS-3688: Reserved status logic still present for originators\n",
      "- WORKS-3687: Work Order by Worker Report --> Error Message when attempting to export to Excel\n",
      "- WORKS-3686: Orderlist endpoint filtering functionality need to optimize  having an issue error 500 sql time out issue \n",
      "- WORKS-3685: Fix spinner endlessly loading when working with Tron\n",
      "- WORKS-3684: Fix sorting on MT Search page to be for all results not just per page\n",
      "- WORKS-3683: Add a Status column to the table on the bulk action page\n",
      "- WORKS-3682: MT Quick Update List - Fix Console Error\n",
      "- WORKS-3681: MT Incoming Screen - Fix Console Error\n",
      "- WORKS-3680: All Open Work Orders MT only Sproc/ Web Page/ Mobile Page\n",
      "- WORKS-3679: Hours Allocated MT only sproc/ Web Page/ Mobile Page\n",
      "- WORKS-3678: Work Order Backlog for Admin only sproc/ Web page/ Mobile Page\n",
      "- WORKS-3677: Admin Custom Report Generator Sproc / Web Page/ Mobile Page\n",
      "- WORKS-3676: MT Custom Report Generator Sproc / Web Page/ Mobile Page\n",
      "- WORKS-3675: Reserved Statuses removed from tblCustomers default constraints\n",
      "- WORKS-3674: Remove Reserved Statuses - Additional Search\n",
      "- WORKS-3673: Disable apply filters button when there are validation errors\n",
      "- WORKS-3672: Scheduler updates (maybe ideas)\n",
      "- WORKS-3671: Error on Adding New Asset in Inventory Assets\n",
      "- WORKS-3670: Update Logo Storage\n",
      "- WORKS-3669: Inconsistent Work Order Status Returned for Order Approver All Role\n",
      "- WORKS-3668: Error Message on Active Page\n",
      "- WORKS-3667: Active WO List showing future RWO's in error\n",
      "- WORKS-3666: Active Work Order List Status Error\n",
      "- WORKS-3665: Please remove some unused RWO's for OCPS\n",
      "- WORKS-3664: Update the RWO profile to allow power users to see page, presently is crashing if OrgDivID doesn't match\n",
      "- WORKS-3663: Fix \"AI Chat enabled\" setting not saving\n",
      "- WORKS-3662: Fix All Open Work Order Report Results\n",
      "- WORKS-3661: Report_WOReportGenerator 1500ms average duration\n",
      "- WORKS-3660: Fix Exporting with Pagination on Active Pages\n",
      "- WORKS-3659: Remove sorting by description on various pages\n",
      "- WORKS-3658: Implement subresource integrity checking\n",
      "- WORKS-3657: [medium][3 impacted resources] Incoming client certificates should be required to be 'On'\n",
      "- WORKS-3656: [low] Write operation on route use predictable IDs\n",
      "- WORKS-3655: [low][3 impacted resources] Read operation on route use predictable IDs\n",
      "- WORKS-3654: [low][3 impacted resources] Read operation on route use predictable IDs\n"
     ]
    }
   ],
   "source": [
    "# Define the project key and the maximum number of results to retrieve\n",
    "project_key = 'WORKS'  # Replace with your project key\n",
    "max_results = 100  # Adjust as needed\n",
    "\n",
    "# Search for issues in the specified project\n",
    "issues = jira.search_issues(f'project={project_key}')\n",
    "\n",
    "# Print the summary of the retrieved issues\n",
    "print(f\"Found {len(issues)} issues in project {project_key}:\")\n",
    "for issue in issues:\n",
    "    print(f\"- {issue.key}: {issue.fields.summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a44c6268"
   },
   "source": [
    "**Reasoning**:\n",
    "Authenticate to Google Cloud, create a BigQuery client instance, and define your project ID and dataset ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1c99e763"
   },
   "source": [
    "## Setup BigQuery Connection\n",
    "\n",
    "### Subtask:\n",
    "Establish a connection to your Google Cloud project and BigQuery dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 275,
     "status": "ok",
     "timestamp": 1755746623320,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "234e487f",
    "outputId": "36bdf8bd-2dca-4d17-deb2-f4b99e9d1df5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery client created for project: steady-cascade-427621\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.colab import auth\n",
    "\n",
    "# Authenticate to Google Cloud\n",
    "auth.authenticate_user()\n",
    "\n",
    "# Define your Google Cloud project ID and BigQuery dataset ID\n",
    "project_id = 'steady-cascade-427621' # Replace with your project ID\n",
    "dataset_id = 'jira_imports' # Replace with your dataset ID\n",
    "\n",
    "# Create a BigQuery client instance\n",
    "client = bigquery.Client(project=project_id)\n",
    "\n",
    "print(f\"BigQuery client created for project: {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 474,
     "status": "ok",
     "timestamp": 1755746797693,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "83d54cb2",
    "outputId": "c2260bb6-3666-4634-b279-ea7cf881446d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table steady-cascade-427621.jira_imports.works_issues already exists.\n",
      "Data loaded successfully into BigQuery.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Define the table ID\n",
    "table_id = f\"{project_id}.{dataset_id}.works_issues\" # Replace with your table ID\n",
    "\n",
    "# Prepare the data for BigQuery\n",
    "rows_to_insert = []\n",
    "for issue in issues:\n",
    "    # Parse and format timestamps\n",
    "    created_timestamp = datetime.fromisoformat(issue.fields.created.replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "    updated_timestamp = datetime.fromisoformat(issue.fields.updated.replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "\n",
    "    rows_to_insert.append({\n",
    "        \"key\": issue.key,\n",
    "        \"summary\": issue.fields.summary,\n",
    "        \"description\": issue.fields.description,\n",
    "        \"status\": issue.fields.status.name,\n",
    "        \"created\": created_timestamp,\n",
    "        \"updated\": updated_timestamp,\n",
    "        \"priority\": issue.fields.priority.name if issue.fields.priority else None,\n",
    "        \"issue_type\": issue.fields.issuetype.name,\n",
    "        \"reporter_displayName\": issue.fields.reporter.displayName if issue.fields.reporter else None,\n",
    "        \"assignee_displayName\": issue.fields.assignee.displayName if issue.fields.assignee else None,\n",
    "    })\n",
    "\n",
    "# Define the table schema based on the selected fields\n",
    "schema = [\n",
    "    bigquery.SchemaField(\"key\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"summary\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"description\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"status\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"created\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"updated\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"priority\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"issue_type\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"reporter_displayName\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"assignee_displayName\", \"STRING\", mode=\"NULLABLE\"),\n",
    "]\n",
    "\n",
    "# Get the table reference\n",
    "table_ref = client.dataset(dataset_id).table(\"works_issues\")\n",
    "\n",
    "# Check if the table exists, if not, create it\n",
    "try:\n",
    "    client.get_table(table_ref)  # API request\n",
    "    print(f\"Table {table_id} already exists.\")\n",
    "except Exception:\n",
    "    print(f\"Table {table_id} not found, creating table.\")\n",
    "    table = bigquery.Table(table_ref, schema=schema)\n",
    "    table = client.create_table(table)  # API request\n",
    "    print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
    "\n",
    "\n",
    "# Load data into BigQuery\n",
    "errors = client.insert_rows_json(table_ref, rows_to_insert)\n",
    "\n",
    "if errors:\n",
    "    print(\"Errors while inserting rows:\")\n",
    "    for error in errors:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"Data loaded successfully into BigQuery.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21636,
     "status": "ok",
     "timestamp": 1755747025325,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "c2191df6",
    "outputId": "1531a24b-0626-4a1d-e9c2-e1ee253b628a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetched changelogs for 50 issues.\n"
     ]
    }
   ],
   "source": [
    "issues_with_changelog = []\n",
    "for issue in issues:\n",
    "    issue_with_changelog = jira.issue(issue.key, expand='changelog')\n",
    "    issues_with_changelog.append(issue_with_changelog)\n",
    "\n",
    "print(f\"Fetched changelogs for {len(issues_with_changelog)} issues.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1755747810908,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "9ec7c293",
    "outputId": "1afadf28-5122-4eff-f0b3-4045400d6572"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 430 changelog entries.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "changelog_rows_to_insert = []\n",
    "\n",
    "for issue in issues_with_changelog:\n",
    "    if issue.changelog and issue.changelog.histories:\n",
    "        for history in issue.changelog.histories:\n",
    "            created_timestamp = datetime.fromisoformat(history.created.replace('Z', '+00:00')).strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]\n",
    "            for item in history.items:\n",
    "                changelog_rows_to_insert.append({\n",
    "                    \"issue_key\": issue.key,\n",
    "                    \"author_displayName\": history.author.displayName if history.author else None,\n",
    "                    \"created\": created_timestamp,\n",
    "                    \"field\": item.field,\n",
    "                    \"fieldtype\": item.fieldtype,\n",
    "\n",
    "                    \"from_string\": item.fromString,\n",
    "\n",
    "                    \"to_string\": item.toString,\n",
    "                })\n",
    "\n",
    "print(f\"Processed {len(changelog_rows_to_insert)} changelog entries.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1140ba5a"
   },
   "outputs": [],
   "source": [
    "changelog_schema = [\n",
    "    bigquery.SchemaField(\"issue_key\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"author_displayName\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"created\", \"TIMESTAMP\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"field\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"fieldtype\", \"STRING\", mode=\"REQUIRED\"),\n",
    "    bigquery.SchemaField(\"from_value\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"from_string\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"to_value\", \"STRING\", mode=\"NULLABLE\"),\n",
    "    bigquery.SchemaField(\"to_string\", \"STRING\", mode=\"NULLABLE\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1138,
     "status": "ok",
     "timestamp": 1755748087832,
     "user": {
      "displayName": "Ben Seeley",
      "userId": "17702341807416644112"
     },
     "user_tz": 420
    },
    "id": "f945aa3d",
    "outputId": "9c0208b1-d88a-4462-b2be-f426c5dc6d5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changelog table steady-cascade-427621.jira_imports.works_changelog not found, creating table.\n",
      "Created changelog table steady-cascade-427621.jira_imports.works_changelog\n",
      "Changelog data loaded successfully into BigQuery.\n"
     ]
    }
   ],
   "source": [
    "# Define the changelog table ID\n",
    "changelog_table_id = f\"{project_id}.{dataset_id}.works_changelog\"\n",
    "\n",
    "# Get the changelog table reference\n",
    "changelog_table_ref = client.dataset(dataset_id).table(\"works_changelog\")\n",
    "\n",
    "# Check if the changelog table exists, if not, create it\n",
    "try:\n",
    "    client.get_table(changelog_table_ref)  # API request\n",
    "    print(f\"Changelog table {changelog_table_id} already exists.\")\n",
    "except Exception:\n",
    "    print(f\"Changelog table {changelog_table_id} not found, creating table.\")\n",
    "    changelog_table = bigquery.Table(changelog_table_ref, schema=changelog_schema)\n",
    "    changelog_table = client.create_table(changelog_table)  # API request\n",
    "    print(f\"Created changelog table {changelog_table.project}.{changelog_table.dataset_id}.{changelog_table.table_id}\")\n",
    "\n",
    "\n",
    "# Load changelog data into BigQuery\n",
    "changelog_errors = client.insert_rows_json(changelog_table_ref, changelog_rows_to_insert)\n",
    "\n",
    "if changelog_errors:\n",
    "    print(\"Errors while inserting changelog rows:\")\n",
    "    for error in changelog_errors:\n",
    "        print(error)\n",
    "else:\n",
    "    print(\"Changelog data loaded successfully into BigQuery.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ae88d4db"
   },
   "source": [
    "## Load Changelog Data to BigQuery\n",
    "\n",
    "### Subtask:\n",
    "Load the transformed changelog data into the new BigQuery table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "745fae56"
   },
   "source": [
    "**Reasoning**:\n",
    "Define the schema for the BigQuery table based on the fields extracted from the changelog data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3b70a606"
   },
   "source": [
    "## Define BigQuery Changelog Table Schema\n",
    "\n",
    "### Subtask:\n",
    "Define the schema for the new BigQuery table that will store the changelog data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0e2fada1"
   },
   "source": [
    "**Reasoning**:\n",
    "Initialize an empty list, iterate through the issues with changelogs, iterate through the changelog entries for each issue, extract and format the relevant fields for each changelog item, and append the flattened data to the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fd137d41"
   },
   "source": [
    "## Transform changelog data\n",
    "\n",
    "### Subtask:\n",
    "Process the extracted changelog data to flatten and structure it for BigQuery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9d28ac06"
   },
   "source": [
    "## Load Data to BigQuery\n",
    "\n",
    "### Subtask:\n",
    "Load the extracted Jira data into your specified BigQuery table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7a554e9"
   },
   "source": [
    "# Task\n",
    "Import Jira issues and their changelogs into separate BigQuery tables. Modify the timestamp format of the Jira issue data to 'YYYY-MM-DD HH:MM[:SS[.SSSSSS]]' to resolve import errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "324a5cb2"
   },
   "source": [
    "## Extract jira changelogs\n",
    "\n",
    "### Subtask:\n",
    "Fetch the changelog for each issue from Jira using the Jira API.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72ed65e9"
   },
   "source": [
    "**Reasoning**:\n",
    "Iterate through the fetched issues and retrieve the changelog for each issue using the Jira API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "66d7d82f"
   },
   "source": [
    "## Transform changelog data\n",
    "\n",
    "### Subtask:\n",
    "Process the extracted changelog data to flatten and structure it for BigQuery.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "89b88cf5"
   },
   "source": [
    "**Reasoning**:\n",
    "Initialize an empty list, iterate through the issues with changelogs, iterate through the changelog entries for each issue, extract and format the relevant fields for each changelog item, and append the flattened data to the list.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e83c438c"
   },
   "source": [
    "**Reasoning**:\n",
    "The previous code failed because the attribute `_from` does not exist in the `item` object. I need to access the `from` attribute directly. I will regenerate the full code block with this correction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7997db52"
   },
   "source": [
    "**Reasoning**:\n",
    "The previous code failed again because the attribute `From` also does not exist. The correct attribute for the 'from' value in the changelog item should be `item.from_`. I will regenerate the full code block with this correction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42436467"
   },
   "source": [
    "**Reasoning**:\n",
    "The previous attempts to access the 'from' attribute of the changelog item have failed. I need to inspect the `item` object to understand its structure and identify the correct attribute name for the 'from' value. I will print the `item` object to examine its attributes.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
